{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tamar\\anaconda3\\envs\\adl\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\tamar\\anaconda3\\envs\\adl\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  data handling (mean, std), images loaded in range [0,1] normalize to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\ttransforms.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "\t\t\t\t\t\t\t\t\t\tdownload=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "\t\t\t\t\t\t\t\t\t\tdownload=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t\t\t  shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\t\t\t shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "\t\t   'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "\timg = img / 2 + 0.5 \t# unnormalize\n",
    "\tnpimg = img.numpy()\n",
    "\tplt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# channels in, channels out, kernel size\n",
    "\t\tself.conv1 = nn.Conv2d(3, 6, 5)\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\t\tself.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "\t\tself.fc2 = nn.Linear(120, 84)\n",
    "\t\tself.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(F.relu(self.conv1(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = torch.flatten(x, 1)\t\t# flatten all except batch\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tx = self.fc3(x)\n",
    "\t\treturn x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tamar\\Desktop\\תואר\\Samester D\\למידה עמוקה יישומית\\תכנות - כיתה\\lecture_7.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tamar/Desktop/%D7%AA%D7%95%D7%90%D7%A8/Samester%20D/%D7%9C%D7%9E%D7%99%D7%93%D7%94%20%D7%A2%D7%9E%D7%95%D7%A7%D7%94%20%D7%99%D7%99%D7%A9%D7%95%D7%9E%D7%99%D7%AA/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA%20-%20%D7%9B%D7%99%D7%AA%D7%94/lecture_7.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\t\t\u001b[39m# loop over dataset multiple times\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tamar/Desktop/%D7%AA%D7%95%D7%90%D7%A8/Samester%20D/%D7%9C%D7%9E%D7%99%D7%93%D7%94%20%D7%A2%D7%9E%D7%95%D7%A7%D7%94%20%D7%99%D7%99%D7%A9%D7%95%D7%9E%D7%99%D7%AA/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA%20-%20%D7%9B%D7%99%D7%AA%D7%94/lecture_7.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \trunning_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tamar/Desktop/%D7%AA%D7%95%D7%90%D7%A8/Samester%20D/%D7%9C%D7%9E%D7%99%D7%93%D7%94%20%D7%A2%D7%9E%D7%95%D7%A7%D7%94%20%D7%99%D7%99%D7%A9%D7%95%D7%9E%D7%99%D7%AA/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA%20-%20%D7%9B%D7%99%D7%AA%D7%94/lecture_7.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader, \u001b[39m0\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tamar/Desktop/%D7%AA%D7%95%D7%90%D7%A8/Samester%20D/%D7%9C%D7%9E%D7%99%D7%93%D7%94%20%D7%A2%D7%9E%D7%95%D7%A7%D7%94%20%D7%99%D7%99%D7%A9%D7%95%D7%9E%D7%99%D7%AA/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA%20-%20%D7%9B%D7%99%D7%AA%D7%94/lecture_7.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \t\tinputs, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tamar/Desktop/%D7%AA%D7%95%D7%90%D7%A8/Samester%20D/%D7%9C%D7%9E%D7%99%D7%93%D7%94%20%D7%A2%D7%9E%D7%95%D7%A7%D7%94%20%D7%99%D7%99%D7%A9%D7%95%D7%9E%D7%99%D7%AA/%D7%AA%D7%9B%D7%A0%D7%95%D7%AA%20-%20%D7%9B%D7%99%D7%AA%D7%94/lecture_7.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \t\toptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "run_train = True\n",
    "if run_train:\n",
    "\tfor epoch in range(2):\t\t# loop over dataset multiple times\n",
    "\n",
    "\t\trunning_loss = 0.0\n",
    "\t\tfor i, data in enumerate(trainloader, 0):\n",
    "\t\t\tinputs, labels = data\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\toutputs = net(inputs)\n",
    "\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\t\t\tif i % 2000 == 1999:\n",
    "\t\t\t\tprint(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "\t\t\t\trunning_loss = 0.0\n",
    "\n",
    "\tprint('Finished Training')\n",
    "\n",
    "\ttorch.save(net.state_dict(), PATH)\n",
    "\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  truck truck truck truck\n"
     ]
    }
   ],
   "source": [
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
